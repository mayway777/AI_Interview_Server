import os
import shutil
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Request
from fastapi.responses import JSONResponse, StreamingResponse, Response
from werkzeug.utils import secure_filename
import cv2
from pathlib import Path
from typing import Optional, Generator,Tuple
import json
from io import BytesIO
from PIL import Image
from urllib.parse import unquote
import numpy as np
import asyncio
from contextlib import asynccontextmanager
from filelock import FileLock 
from pymongo import MongoClient
from bson import ObjectId
import os
import logging

# ë¶„ì„ ëª¨ë“ˆ Import
from analysis.DB import video_db
from analysis.Eye import track_eyes, reset_gaze_count, get_current_gaze_stats
from analysis.emotion import emotion_recognition, get_emotion_percentages, get_lean_percentages, load_emotion_models
from analysis.audio_analysis import convert_to_wav_with_denoise, analyze_speed, load_whisper_model
from analysis.Silent_FillerWords import analyze_audio, Silent_load_models
from analysis.Volatility import calculate_pitch_variability
from analysis.feedback import InterviewEvaluator

global_executor = ThreadPoolExecutor(max_workers=8) 

# ìƒìˆ˜ ì •ì˜
UPLOAD_FOLDER = './uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

MODEL_LOCK_FILE = "model_load.lock"
CHUNK_SIZE = 1024 * 1024     # 1MB ì²­í¬ í¬ê¸°  

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ëª¨ë¸ ë¡œë“œ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ ê°œì„ ëœ ë¼ì´í”„ì‚¬ì´í´ í•¸ë“¤ëŸ¬"""
    # íŒŒì¼ ì ê¸ˆìœ¼ë¡œ ë™ì‹œ ë¡œë“œ ë°©ì§€
    with FileLock(MODEL_LOCK_FILE + ".lock"):
        if not os.path.exists(MODEL_LOCK_FILE):
            print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
            load_whisper_model()
            load_emotion_models()
            Silent_load_models()
            Path(MODEL_LOCK_FILE).touch()  # ì™„ë£Œ í‘œì‹œ
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    yield
    
    # ì„œë²„ ì¢…ë£Œ ì‹œ ì ê¸ˆ íŒŒì¼ ì •ë¦¬
    if os.path.exists(MODEL_LOCK_FILE):
        os.remove(MODEL_LOCK_FILE)

app = FastAPI(lifespan=lifespan)

logging.basicConfig(level=logging.INFO)

def is_model_loaded():
    """ê°ì • ì¸ì‹ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    try:
        return track_eyes is not None and emotion_recognition is not None
    except:
        return False

def initialize_analysis_document(userUid: str, resumeUid: str, resume_title: str, job_code: str, timestamp: str, company: Optional[str] = None):
    """ì´ˆê¸° ë¶„ì„ ë¬¸ì„œ ìƒì„±"""
    initial_doc = {
        "uid": userUid,
        "self_id": resumeUid,
        "title": resume_title,
        "job_code": job_code,
        "time": timestamp,
        "company": company,
        userUid: {}
    }
    return video_db.create_initial_document(initial_doc)

def save_uploaded_file(file: UploadFile, uid: str, filename: str) -> Tuple[str, str]:
    """íŒŒì¼ì„ ì €ì¥í•˜ê³  íŒŒì¼ ê²½ë¡œì™€ ì•ˆì „í•œ íŒŒì¼ëª… ë°˜í™˜"""
    user_folder = os.path.join(UPLOAD_FOLDER, uid)
    os.makedirs(user_folder, exist_ok=True)
    
    secure_name = secure_filename(filename)
    file_path = os.path.join(user_folder, secure_name)
    
    with open(file_path, "wb") as buffer:
        file.file.seek(0)
        shutil.copyfileobj(file.file, buffer)
    
    return file_path, secure_name

def analyze_audio_features(wav_file_path: str, job_code: str, current_question: str, resume_data: list):
    """ì˜¤ë””ì˜¤ íŠ¹ì§• ë¶„ì„"""
    try:
        # ìŒì„± ë³€ë™ì„± ë¶„ì„
        voice_variability = calculate_pitch_variability(wav_file_path)
        
        # ë§í•˜ê¸° ì†ë„ ë¶„ì„
        result_text, words_per_minute, speed_difference = analyze_speed(wav_file_path)
        
        # ì¶”ì„ìƒˆ, ì¹¨ë¬µ ë¶„ì„
        filler_count, silence_count = analyze_audio(wav_file_path)

        # GPT í‰ê°€ ìˆ˜í–‰
        try:
            load_dotenv('.env.local')
            OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
            evaluator = InterviewEvaluator(OPENAI_API_KEY)
            
            gpt_evaluation = evaluator.evaluate_answer(
                job_code=job_code,
                resume_data=resume_data,
                question=current_question,
                answer=result_text
            )
        except Exception as gpt_error:
            print(f"GPT í‰ê°€ ì‹¤íŒ¨: {str(gpt_error)}")
            gpt_evaluation = {
                "error": "GPT í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": str(gpt_error)
            }

        return {
            "ë‹µë³€": result_text,
            "ë§í•˜ê¸°ì†ë„": words_per_minute,
            "í‰ì†ëŒ€ë¹„ì°¨ì´": speed_difference,
            "ì¶”ì„ìƒˆê°¯ìˆ˜": filler_count,
            "ì¹¨ë¬µê°¯ìˆ˜": silence_count,
            "ëª©ì†Œë¦¬ë³€ë™ì„±": voice_variability,
            "GPT_í‰ê°€": gpt_evaluation
        }
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            "ë‹µë³€": None,
            "ë§í•˜ê¸°ì†ë„": None,
            "í‰ì†ëŒ€ë¹„ì°¨ì´": None,
            "ì¶”ì„ìƒˆê°¯ìˆ˜": None,
            "ì¹¨ë¬µê°¯ìˆ˜": None,
            "ëª©ì†Œë¦¬ë³€ë™ì„±": None,
            "GPT_í‰ê°€": None
        }

def analyze_video_features(file_path: str):
    """ì˜ìƒ íŠ¹ì§• ë¶„ì„"""
    # ì‹œì„  ì¶”ì  ì¹´ìš´í„° ì´ˆê¸°í™”
    reset_gaze_count()
    
    try:
        cap = cv2.VideoCapture(file_path)
        frame_number = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_number += 1
            if frame_number % 6 == 0:
                emotion_recognition(frame)
                track_eyes(frame)

        cap.release()

        # ìµœì¢… ì‹œì„  í†µê³„ ê°€ì ¸ì˜¤ê¸°
        final_gaze_stats = get_current_gaze_stats()

        return {
            "ê°ì •_%": get_emotion_percentages(),
            "ë¨¸ë¦¬ê¸°ìš¸ê¸°_%": get_lean_percentages(),
            "ì•„ì´íŠ¸ë˜í‚¹_%": final_gaze_stats['percentages']
        }
    except Exception as e:
        print(f"ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            "ê°ì •_%": None,
            "ë¨¸ë¦¬ê¸°ìš¸ê¸°_%": None,
            "ì•„ì´íŠ¸ë˜í‚¹_%": None
        }

def process_analysis(
    userUid, resumeUid, job_code, resume_title, 
    timestamp, company, questions, files, data
):
    """ë¶„ì„ ì²˜ë¦¬ í•¨ìˆ˜"""
    # ëª¨ë¸ ë¡œë”© í™•ì¸
    if not is_model_loaded():
        load_whisper_model()
        load_emotion_models()
        Silent_load_models()

    try:
        # ì´ˆê¸° ë¬¸ì„œ ìƒì„±
        doc_id = initialize_analysis_document(userUid, resumeUid, resume_title, job_code, timestamp, company)
        if not doc_id:
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "message": "ì´ˆê¸° ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨"
                }
            )

        # ê³µí†µ ì •ë³´ ìƒì„±
        combined_title = f"{resume_title}_{timestamp}"

        # íŒŒì¼ ì €ì¥ ë° ë¶„ì„
        analyzed_count = 0
        for i, (question, file) in enumerate(zip(questions, files), 1):
            try:
                # ë¹ˆ íŒŒì¼ì´ë‚˜ ì§ˆë¬¸ ê±´ë„ˆë›°ê¸°
                if not file or not question:
                    continue
                
                original_extension = file.filename.split('.')[-1]
                filename = f"{combined_title}_video{i}.{original_extension}"
                
                # ë™ì¼í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                file_path, secure_name = save_uploaded_file(file, userUid, filename)
                resume_data = json.loads(data)
                
                # WAV íŒŒì¼ë¡œ ë³€í™˜
                wav_file_path = convert_to_wav_with_denoise(file_path)
                
                with ThreadPoolExecutor(max_workers=2) as executor:
                    # ë³‘ë ¬ë¡œ ì˜¤ë””ì˜¤ì™€ ë¹„ë””ì˜¤ ë¶„ì„
                    audio_future = executor.submit(
                        analyze_audio_features, 
                        wav_file_path, 
                        job_code, 
                        question, 
                        resume_data
                    )
                    
                    video_future = executor.submit(
                        analyze_video_features, 
                        file_path
                    )
                    
                    # ê²°ê³¼ ëŒ€ê¸°
                    audio_analysis = audio_future.result()
                    video_analysis = video_future.result()

                # ë¶„ì„ ê²°ê³¼ í†µí•© (íŒŒì¼ ê°ì²´ ì œì™¸)
                analysis_result = {
                    "video_number": i,
                    "video_filename": secure_name,
                    "question": question,
                    "ë‹µë³€": audio_analysis.get("ë‹µë³€"),
                    "ë§í•˜ê¸°ì†ë„": audio_analysis.get("ë§í•˜ê¸°ì†ë„"),
                    "í‰ì†ëŒ€ë¹„ì°¨ì´": audio_analysis.get("í‰ì†ëŒ€ë¹„ì°¨ì´"),
                    "ì¶”ì„ìƒˆê°¯ìˆ˜": audio_analysis.get("ì¶”ì„ìƒˆê°¯ìˆ˜"),
                    "ì¹¨ë¬µê°¯ìˆ˜": audio_analysis.get("ì¹¨ë¬µê°¯ìˆ˜"),
                    "ëª©ì†Œë¦¬ë³€ë™ì„±": audio_analysis.get("ëª©ì†Œë¦¬ë³€ë™ì„±"),
                    "ê°ì •_%": video_analysis.get("ê°ì •_%"),
                    "ë¨¸ë¦¬ê¸°ìš¸ê¸°_%": video_analysis.get("ë¨¸ë¦¬ê¸°ìš¸ê¸°_%"),
                    "ì•„ì´íŠ¸ë˜í‚¹_%": video_analysis.get("ì•„ì´íŠ¸ë˜í‚¹_%"),
                    "GPT_í‰ê°€": audio_analysis.get("GPT_í‰ê°€")
                }
                
                # DBì— ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
                success = video_db.update_analysis_results(doc_id, userUid, i, analysis_result)
                if success:
                    analyzed_count += 1
                    print(f"ë¹„ë””ì˜¤ {i} ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„±ê³µ")

                # ì„ì‹œ WAV íŒŒì¼ ì‚­ì œ
                if os.path.exists(wav_file_path):
                    os.remove(wav_file_path)

            except Exception as e:
                print(f"ì˜ìƒ {i} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ê²°ê³¼ ì €ì¥
                error_result = {
                    "video_number": i,
                    "video_filename": filename if 'filename' in locals() else f"error_video{i}",
                    "question": question,
                    "ë‹µë³€": None,
                    "ë§í•˜ê¸°ì†ë„": None,
                    "í‰ì†ëŒ€ë¹„ì°¨ì´": None,
                    "ì¶”ì„ìƒˆê°¯ìˆ˜": None,
                    "ì¹¨ë¬µê°¯ìˆ˜": None,
                    "ëª©ì†Œë¦¬ë³€ë™ì„±": None,
                    "ê°ì •_%": None,
                    "ë¨¸ë¦¬ê¸°ìš¸ê¸°_%": None,
                    "ì•„ì´íŠ¸ë˜í‚¹_%": None,
                    "GPT_í‰ê°€": None
                }
                video_db.update_analysis_results(doc_id, userUid, i, error_result)

        return JSONResponse(
            content={
                "success": True,
                "message": f"ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {analyzed_count}ê°œì˜ ì˜ìƒì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "doc_id": str(doc_id),
                "analyzed_count": analyzed_count,
                "total_videos": len([q for q in questions if q])
            }
        )

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
        )

@app.post("/analyze")
async def analyze_video(
    userUid: str = Form(...),
    resumeUid: str = Form(...),
    job_code: str = Form(...),
    resume_title: str = Form(...),
    timestamp: str = Form(...),
    company: str = Form(None),
    question_0: str = Form(None),
    question_1: str = Form(None),
    question_2: str = Form(None),
    question_3: str = Form(None),
    videoFile_0: UploadFile = File(None),
    videoFile_1: UploadFile = File(None),
    videoFile_2: UploadFile = File(None),
    videoFile_3: UploadFile = File(None),
    data: str = Form(...),
):
    # ì§ˆë¬¸ê³¼ íŒŒì¼ ìŒ ê²€ì¦
    questions = [question_0, question_1, question_2, question_3]
    files = [videoFile_0, videoFile_1, videoFile_2, videoFile_3]
    
    print(questions)
    print(files)
    # ì§ˆë¬¸ì´ ìˆëŠ”ë° íŒŒì¼ì´ ì—†ê±°ë‚˜, íŒŒì¼ì´ ìˆëŠ”ë° ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš° ì²´í¬
    valid_pairs = [(q, f) for q, f in zip(questions, files) if q and f]
    
    if len(valid_pairs) < 1:
        return JSONResponse(
            status_code=400,
            content={
                "success": False,
                "message": "ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§ˆë¬¸ê³¼ ë¹„ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
            }
        )

    # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§ˆë¬¸-íŒŒì¼ ìŒì´ ìˆëŠ”ì§€ í™•ì¸
    valid_pairs = [(q, f) for q, f in zip(questions, files) if q and f]
    if not valid_pairs:
        return JSONResponse(
            status_code=400,
            content={
                "success": False,
                "message": "ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§ˆë¬¸ê³¼ ë¹„ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
            }
        )

    # ê¸€ë¡œë²Œ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‘ì—… ì‹¤í–‰
    future = global_executor.submit(
        process_analysis, 
        userUid, resumeUid, job_code, resume_title, 
        timestamp, company, questions, files, data
    )
    
    # ê²°ê³¼ ëŒ€ê¸°
    result = await asyncio.wrap_future(future)
    return result

@app.get('/health')
async def health_check():
    return {'status': 'ok'}

@app.post("/video/preview")
async def get_video_preview(request: Request):
   body = await request.json()
   uid = body.get('uid')
   filename = body.get('filename')
   
   if not uid or not filename:
       raise HTTPException(status_code=400, detail="Missing uid or filename")
   
   decoded_filename = unquote(filename)
   
   video_path = os.path.join(UPLOAD_FOLDER, uid, decoded_filename)
   
   if not os.path.exists(video_path):
       raise HTTPException(status_code=404, detail="Video not found")
   
   try:
       # ë¹„ë””ì˜¤ì˜ ì²« í”„ë ˆì„ ì¶”ì¶œ
       cap = cv2.VideoCapture(video_path)
       ret, frame = cap.read()
       cap.release()
       
       if not ret:
           raise HTTPException(status_code=500, detail="Could not read video frame")
       
       # BGRì—ì„œ RGBë¡œ ë³€í™˜
       frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
       image = Image.fromarray(frame_rgb)
       
       # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
       img_byte_arr = BytesIO()
       image.save(img_byte_arr, format='JPEG', quality=85)
       img_byte_arr.seek(0)
       
       return Response(
           content=img_byte_arr.getvalue(),
           media_type="image/jpeg"
       )
       
   except Exception as e:
       raise HTTPException(status_code=500, detail=str(e))

@app.post("/video")
async def stream_video(request: Request):
   body = await request.json()
   uid = body.get('uid')
   filename = body.get('filename')
   
   if not uid or not filename:
       raise HTTPException(status_code=400, detail="Missing uid or filename")
   
   decoded_filename = unquote(filename)
   
   video_path = os.path.join(UPLOAD_FOLDER, uid, decoded_filename)
   
   if not os.path.exists(video_path):
       raise HTTPException(status_code=404, detail="Video not found")
   
   file_size = os.path.getsize(video_path)
   
   # Range í—¤ë” ì²˜ë¦¬
   range_header = request.headers.get('range')
   
   if range_header:
       start, end = range_header.replace('bytes=', '').split('-')
       start = int(start)
       end = int(end) if end else min(start + CHUNK_SIZE, file_size - 1)
   else:
       start = 0
       end = min(CHUNK_SIZE, file_size - 1)
       
   # ì‹¤ì œ ì „ì†¡í•  í¬ê¸°
   chunk_size = end - start + 1
   
   headers = {
       'Content-Range': f'bytes {start}-{end}/{file_size}',
       'Accept-Ranges': 'bytes',
       'Content-Length': str(chunk_size),
       'Content-Type': 'video/webm',
   }
   
   return StreamingResponse(
       video_chunk_generator(video_path, start, end),
       status_code=206 if range_header else 200,
       headers=headers
   )

def video_chunk_generator(file_path: str, start: int, end: int) -> Generator[bytes, None, None]:
   """ë¹„ë””ì˜¤ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ìƒì„±í•˜ëŠ” ì œë„ˆë ˆì´í„°"""
   with open(file_path, 'rb') as video_file:
       video_file.seek(start)
       remaining = end - start + 1
       while remaining > 0:
           # 64KB ë‹¨ìœ„ë¡œ ì½ê¸°
           chunk_size = min(64 * 1024, remaining)
           data = video_file.read(chunk_size)
           if not data:
               break
           remaining -= len(data)
           yield data

@app.delete("/delete/{doc_id}")
async def delete_interview(doc_id: str):
    try:
        # MongoDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        mongo_uri = os.environ.get('MONGODB_URI')
        if not mongo_uri:
            raise HTTPException(status_code=500, detail="MongoDB URIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        client = MongoClient(mongo_uri)
        db = client['EmpAI']
        collection = db['video_analysis']
        
        # ObjectId ìœ íš¨ì„± ê²€ì‚¬
        if not ObjectId.is_valid(doc_id):
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ document IDì…ë‹ˆë‹¤")
        
        # ObjectIdë¡œ ë³€í™˜í•˜ì—¬ ë¬¸ì„œ ì¡°íšŒ
        document = collection.find_one({"_id": ObjectId(doc_id)})
        
        if not document:
            raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        user_uid = document.get('uid')
        if not user_uid:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ë¬¸ì„œ í˜•ì‹ì…ë‹ˆë‹¤")

        # í•´ë‹¹ ë¬¸ì„œì˜ ëª¨ë“  ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        user_videos = document.get(user_uid, {})
        deleted_files = []
        deletion_errors = []

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì˜ìƒë§Œ ì‚­ì œ ì‹œë„
        for video_num, video_data in user_videos.items():
            if isinstance(video_data, dict) and 'video_filename' in video_data:
                filename = video_data['video_filename']
                video_path = os.path.join(UPLOAD_FOLDER, user_uid, filename)
                
                if os.path.exists(video_path):
                    try:
                        os.remove(video_path)
                        deleted_files.append(filename)
                        print(f"ì˜ìƒ {video_num} ì‚­ì œ ì„±ê³µ: {filename}")
                    except Exception as e:
                        error_msg = f"ì˜ìƒ {video_num} ({filename}): {str(e)}"
                        deletion_errors.append(error_msg)
                        print(f"ì˜ìƒ ì‚­ì œ ì‹¤íŒ¨: {error_msg}")

        # ì‚­ì œ ê²°ê³¼ ë°˜í™˜
        if deleted_files:
            success_message = f"ì‚­ì œëœ ì˜ìƒ: {', '.join(deleted_files)}"
            if deletion_errors:
                success_message += f"\nì‚­ì œ ì‹¤íŒ¨: {', '.join(deletion_errors)}"
            
            return JSONResponse(
                content={
                    "success": True,
                    "message": success_message,
                    "deleted_files": deleted_files,
                    "errors": deletion_errors
                }
            )
        else:
            raise HTTPException(
                status_code=404,
                detail="ì‚­ì œí•  ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
            
    except Exception as e:
        print(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
        )
    finally:
        if 'client' in locals():
            client.close()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
    "main:app",
    host="0.0.0.0",
    port=5001,
    workers=1,
    reload=False,
    lifespan="on",
    factory=False,
    log_level="debug"  # ë” ìì„¸í•œ ë¡œê¹…
)